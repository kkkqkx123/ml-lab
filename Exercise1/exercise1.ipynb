{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 编程练习 1：线性回归\n",
    "\n",
    "## 介绍\n",
    "\n",
    "在本次练习中，你将实现线性回归并观察其在数据上的表现。\n",
    "\n",
    "本次作业所需的所有信息都包含在此笔记本中，你将实现的所有代码也将在此笔记本中完成。作业可以直接从此笔记本提交到的评分系统（下面包含代码和说明）。\n",
    "\n",
    "在开始练习之前，我们需要导入本次编程练习所需的所有库。在整个课程中，我们将使用 [`numpy`](http://www.numpy.org/) 进行所有数组和矩阵操作，并使用 [`matplotlib`](https://matplotlib.org/) 进行绘图。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 用于操作目录路径\n",
    "import os\n",
    "import sys\n",
    "sys.path.append('.')\n",
    "# Python 的科学计算和向量计算库\n",
    "import numpy as np\n",
    "\n",
    "# 绘图库\n",
    "from matplotlib import pyplot\n",
    "import matplotlib\n",
    "matplotlib.rcParams['font.sans-serif'] = ['SimHei']  # 或 ['Microsoft YaHei']\n",
    "matplotlib.rcParams['axes.unicode_minus'] = False    # 正确显示负号\n",
    "\n",
    "# 为本次练习编写的库，提供作业提交和其他功能\n",
    "import utils \n",
    "\n",
    "# 定义用于本次练习的提交/评分对象\n",
    "grader = utils.Grader()\n",
    "\n",
    "# 告诉 matplotlib 将图表嵌入到笔记本中\n",
    "%matplotlib inline\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 提交和评分\n",
    "\n",
    "完成作业的每一部分后，请务必将你的解决方案提交给评分系统。\n",
    "\n",
    "对于本次编程练习，你只需要完成练习的第一部分，即实现单变量线性回归。练习的第二部分是可选的，涵盖了多变量线性回归。以下是本次练习每部分的评分细则。\n",
    "\n",
    "**必做练习**\n",
    "\n",
    "| 部分 | 内容                                           | 提交的函数                     | 分数 \n",
    "|------|:-                                             |:-                              | :-:    \n",
    "| 1    | [热身练习](#section1)                         | [`warmUpExercise`](#warmUpExercise)    |  20    \n",
    "| 2    | [单变量的代价计算](#section2)                 | [`computeCost`](#computeCost)         |  20    \n",
    "| 3    | [单变量的梯度下降](#section3)                 | [`gradientDescent`](#gradientDescent) |  20    \n",
    "| 4    | [特征归一化](#section4)                              | [`featureNormalize`](#featureNormalize) | 20      |\n",
    "| 5    | [多变量的代价计算](#section5)                        | [`computeCostMulti`](#computeCostMulti) | 20      |\n",
    "| 6    | [多变量的梯度下降](#section5)                        | [`gradientDescentMulti`](#gradientDescentMulti) |20      |\n",
    "| 7    | [正规方程](#section7)                                | [`normalEqn`](#normalEqn)        | 20      |\n",
    "|      | 总分                                          |                                | 140    \n",
    "你可以多次提交你的解决方案，我们将只考虑最高分。\n",
    "\n",
    "<div class=\"alert alert-block alert-warning\">\n",
    "在本笔记本的每个部分末尾，我们都有一个代码单元格，用于将当前部分的解决方案提交给评分系统。执行该单元格以查看你当前的得分。为了确保你的所有工作被正确提交，你必须至少执行这些单元格一次。每次更新提交的函数时，也必须重新执行这些单元格。\n",
    "</div>\n",
    "\n",
    "\n",
    "## 调试\n",
    "\n",
    "在整个练习过程中，请记住以下几点：\n",
    "\n",
    "- Python 的数组索引从零开始，而不是从一开始（与 OCTAVE/MATLAB 相反）。 \n",
    "\n",
    "- Python 的数组（称为 `list` 或 `tuple`）与 `numpy` 数组之间有重要区别。你应该在所有计算中使用 `numpy` 数组。向量/矩阵操作仅适用于 `numpy` 数组。Python 列表不支持向量操作（需要使用 for 循环）。\n",
    "\n",
    "- 如果在运行时看到许多错误，请检查你的矩阵操作，确保你正在对维度兼容的矩阵进行加法和乘法操作。使用 `shape` 属性打印 `numpy` 数组的维度将有助于你调试。\n",
    "\n",
    "- 默认情况下，`numpy` 将数学运算符解释为元素级运算符。如果你想进行矩阵乘法，需要使用 `numpy` 的 `dot` 函数。例如，如果 `A` 和 `B` 是两个 `numpy` 矩阵，那么矩阵运算 AB 是 `np.dot(A, B)`。注意，对于二维矩阵或向量（一维），这也等价于 `A@B`（需要 Python >= 3.5）。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"section1\"></a>\n",
    "## 1 简单的 python 和 `numpy` 函数\n",
    "\n",
    "本次作业的第一部分将让你练习 python 和 `numpy` 的语法以及作业提交流程。在下一个单元格中，你将找到一个 `python` 函数的框架。通过填写以下代码将其修改为返回一个 5 x 5 的单位矩阵：\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def warmUpExercise():\n",
    "    \"\"\"\n",
    "    Python 中的示例函数，用于计算单位矩阵。\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    A : array_like\n",
    "        5x5 的单位矩阵。\n",
    "    \n",
    "    Instructions\n",
    "    ------------\n",
    "    返回 5x5 的单位矩阵。\n",
    "    \"\"\"    \n",
    "    # ======== 在此处编写代码 ======\n",
    "    A = np.eye(5)\n",
    "    \n",
    "    # ==============================\n",
    "    return A"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "前一个单元格仅定义了函数 `warmUpExercise`。我们现在可以通过执行以下单元格来运行它以查看其输出。你应该会看到类似于以下的输出：\n",
    "\n",
    "```python\n",
    "array([[ 1.,  0.,  0.,  0.,  0.],\n",
    "       [ 0.,  1.,  0.,  0.,  0.],\n",
    "       [ 0.,  0.,  1.,  0.,  0.],\n",
    "       [ 0.,  0.,  0.,  1.,  0.],\n",
    "       [ 0.,  0.,  0.,  0.,  1.]])\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0.],\n",
       "       [0., 0., 1., 0., 0.],\n",
       "       [0., 0., 0., 1., 0.],\n",
       "       [0., 0., 0., 0., 1.]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "warmUpExercise()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 提交解决方案\n",
    "\n",
    "完成练习的某一部分后，你可以通过首先将你修改的函数添加到 `grader` 对象中，然后通过grader.grade()提交你的答案。\n",
    "\n",
    "你可以多次提交你的解决方案，我们只会考虑最高分。\n",
    "\n",
    "执行下一个单元格以对你在本次练习第一部分中的解决方案进行评分。\n",
    "\n",
    "*你现在应该提交你的解决方案。*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "本地评分结果\n",
      "\n",
      "                                  Part Name | Score    | Result\n",
      "                                  --------- | -------- | --------\n",
      "                           Warm up exercise | 20       | 通过\n",
      "          Computing Cost (for one variable) | 0        | 未通过\n",
      "        Gradient Descent (for one variable) | 0        | 未通过\n",
      "                      Feature Normalization | 0        | 未通过\n",
      "    Computing Cost (for multiple variables) | 0        | 未通过\n",
      "  Gradient Descent (for multiple variables) | 0        | 未通过\n",
      "                           Normal Equations | 0        | 未通过\n",
      "\n",
      "总分: 20 / 140\n"
     ]
    }
   ],
   "source": [
    "# 将所有已实现的函数添加到 grader 对象中\n",
    "grader[1] = warmUpExercise\n",
    "\n",
    "# 本地评分\n",
    "grader.grade()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 单变量线性回归\n",
    "\n",
    "现在，你将实现单变量线性回归来预测食品卡车的利润。假设你是一家餐厅连锁店的 CEO，正在考虑在不同城市开设新店。该连锁店已经在多个城市拥有卡车，并且你拥有这些城市的人口和利润数据。你希望使用这些数据来帮助你选择下一个扩展的城市。\n",
    "\n",
    "文件 `Data/ex1data1.txt` 包含了我们线性回归问题的数据集。第一列是城市的人口（以 10,000 为单位），第二列是该城市食品卡车的利润（以 $10,000 为单位）。利润的负值表示亏损。\n",
    "\n",
    "我们为你提供了加载此数据所需的代码。数据集从数据文件中加载到变量 `x` 和 `y` 中："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 读取逗号分隔的数据\n",
    "data = np.loadtxt(os.path.join('Data', 'ex1data1.txt'), delimiter=',')\n",
    "X, y = data[:, 0], data[:, 1]\n",
    "\n",
    "m = y.size  # 训练样本的数量"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 绘制数据\n",
    "\n",
    "在开始任何任务之前，通常通过可视化数据来理解数据是很有用的。对于这个数据集，由于它只有两个属性（利润和人口）可以绘制，因此可以使用散点图来可视化数据。你在现实生活中遇到的许多其他问题是多维的，无法在二维图上绘制。有许多 Python 的绘图库（请参阅这篇[博客文章](https://blog.modeanalytics.com/python-data-visualization-libraries/)以了解最流行的库的总结）。\n",
    "\n",
    "在本课程中，我们将专门使用 `matplotlib` 进行所有绘图。`matplotlib` 是 Python 中最流行的科学绘图库之一，拥有广泛的工具和功能来制作精美的图表。`pyplot` 是 `matplotlib` 中的一个模块，它提供了一个简化的接口，用于完成 `matplotlib` 最常见的绘图任务，模仿 MATLAB 的绘图接口。\n",
    "\n",
    "<div class=\"alert alert-block alert-warning\">\n",
    "你可能已经注意到，我们在本次练习的开头使用命令 `from matplotlib import pyplot` 导入了 `pyplot` 模块。这种方式相对不常见，如果你查看其他地方的 Python 代码或 `matplotlib` 教程，你会发现该模块通常被命名为 `plt`。这是通过使用导入命令 `import matplotlib.pyplot as plt` 进行模块重命名实现的。在本课程练习中，我们不会使用 `pyplot` 模块的简称，但你应该了解这种与常规的偏离。\n",
    "</div>\n",
    "\n",
    "在接下来的部分中，你的第一个任务是完成下面的 `plotData` 函数。修改该函数并填写以下代码：\n",
    "\n",
    "```python\n",
    "    pyplot.plot(x, y, 'ro', ms=10, mec='k')\n",
    "    pyplot.ylabel('Profit in $10,000')\n",
    "    pyplot.xlabel('Population of City in 10,000s')\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotData(x, y):\n",
    "    \"\"\"\n",
    "    绘制数据点 x 和 y 到一个新图中。绘制数据点并为图的坐标轴设置人口和利润的标签。\n",
    "    \n",
    "    参数\n",
    "    ----------\n",
    "    x : array_like\n",
    "        x 轴的数据点值。\n",
    "\n",
    "    y : array_like\n",
    "        y 轴的数据点值。注意 x 和 y 应该具有相同的大小。\n",
    "    \n",
    "    说明\n",
    "    ------------\n",
    "    使用 \"figure\" 和 \"plot\" 函数将训练数据绘制到图中。使用 \"xlabel\" 和 \"ylabel\" 函数设置坐标轴标签。\n",
    "    假设人口和收入数据已作为 x 和 y 参数传递给此函数。\n",
    "    \n",
    "    提示\n",
    "    ----\n",
    "    你可以使用 'ro' 选项与 plot 一起使用，以使标记显示为红色圆圈。此外，你可以通过使用 plot(..., 'ro', ms=10) 来使标记更大，其中 `ms` 指的是标记大小。\n",
    "    你还可以使用 `mec` 属性设置标记边缘颜色。\n",
    "    \"\"\"\n",
    "    fig = pyplot.figure()  # 打开一个新图\n",
    "    \n",
    "    # ====================== 在此处填写你的代码 ======================= \n",
    "    pyplot.plot(x, y, 'ro', ms=10, mec='k')\n",
    "    pyplot.ylabel('Profit in $10,000')\n",
    "    pyplot.xlabel('Population of City in 10,000s')\n",
    "\n",
    "    \n",
    "\n",
    "    # =============================================================\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "现在运行定义的函数并使用加载的数据来可视化数据。最终结果应如下图所示：\n",
    "\n",
    "![](Figures/dataset1.png)\n",
    "\n",
    "执行下一个单元格以可视化数据。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotData(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "要快速了解 `matplotlib` 的 plot 函数以及可以为其提供的参数，\n",
    "为了将标记设置为红色圆圈，我们在 `plot` 函数中使用了选项 `'or'`。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"section2\"></a>\n",
    "### 2.2 梯度下降\n",
    "\n",
    "在这一部分中，你将使用梯度下降来拟合线性回归参数 $\\theta$ 到我们的数据集。\n",
    "\n",
    "#### 2.2.1 更新公式\n",
    "\n",
    "线性回归的目标是最小化代价函数\n",
    "\n",
    "$$ J(\\theta) = \\frac{1}{2m} \\sum_{i=1}^m \\left( h_{\\theta}(x^{(i)}) - y^{(i)}\\right)^2$$\n",
    "\n",
    "其中假设函数 $h_\\theta(x)$ 由线性模型给出\n",
    "$$ h_\\theta(x) = \\theta^Tx = \\theta_0 + \\theta_1 x_1$$\n",
    "\n",
    "回顾一下，模型的参数是 $\\theta_j$ 值。这些是你将调整以最小化代价 $J(\\theta)$ 的值。实现这一目标的一种方法是使用批量梯度下降算法。在批量梯度下降中，每次迭代执行以下更新：\n",
    "\n",
    "$$ \\theta_j = \\theta_j - \\alpha \\frac{1}{m} \\sum_{i=1}^m \\left( h_\\theta(x^{(i)}) - y^{(i)}\\right)x_j^{(i)} \\qquad \\text{同时更新 } \\theta_j \\text{ 对于所有 } j$$\n",
    "\n",
    "通过梯度下降的每一步，你的参数 $\\theta_j$ 会更接近能够实现最低代价 $J(\\theta)$ 的最优值。\n",
    "\n",
    "<div class=\"alert alert-block alert-warning\">\n",
    "**实现注意事项：** 我们在 Python 的 `numpy` 中将每个样本存储为 $X$ 矩阵中的一行。为了考虑截距项 ($\\theta_0$)，我们在 $X$ 中添加了一个额外的第一列，并将其设置为全为 1。这使我们可以将 $\\theta_0$ 简单地视为另一个“特征”。\n",
    "</div>\n",
    "\n",
    "\n",
    "#### 2.2.2 实现\n",
    "\n",
    "我们已经为线性回归设置了数据。在下面的单元格中，我们为数据添加了另一个维度，以适应 $\\theta_0$ 截距项。不要多次执行此单元格。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 向 X 添加一列全为 1 的列。numpy 函数 stack 用于沿给定轴连接数组。\n",
    "# 第一个轴（axis=0）指的是行（训练样本）\n",
    "# 第二个轴（axis=1）指的是列（特征）。\n",
    "X = np.stack([np.ones(m), X], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"section2\"></a>\n",
    "#### 2.2.3 计算代价 $J(\\theta)$\n",
    "\n",
    "当你执行梯度下降以最小化代价函数 $J(\\theta)$ 时，通过计算代价来监控收敛情况是很有帮助的。在本节中，你将实现一个函数来计算 $J(\\theta)$，以便检查梯度下降实现的收敛性。\n",
    "\n",
    "你的下一个任务是完成函数 `computeCost` 的代码，该函数计算 $J(\\theta)$。在执行此操作时，请记住变量 $X$ 和 $y$ 不是标量值。$X$ 是一个矩阵，其行表示训练集中的示例，而 $y$ 是一个向量，其每个元素表示 $X$ 中给定行的值。\n",
    "<a id=\"computeCost\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeCost(X, y, theta):\n",
    "    \"\"\"\n",
    "    计算线性回归的代价函数。使用 theta 作为参数来拟合 X 和 y 中的数据点。\n",
    "    \n",
    "    参数\n",
    "    ----------\n",
    "    X : array_like\n",
    "        输入数据集，形状为 (m x n+1)，其中 m 是样本数量，n 是特征数量。\n",
    "        我们假设特征中已经附加了一列全为 1 的向量，因此有 n+1 列。\n",
    "    \n",
    "    y : array_like\n",
    "        函数在每个数据点的值。是一个形状为 (m, ) 的向量。\n",
    "    \n",
    "    theta : array_like\n",
    "        回归函数的参数。是一个形状为 (n+1, ) 的向量。\n",
    "    \n",
    "    返回值\n",
    "    -------\n",
    "    J : float\n",
    "        回归代价函数的值。\n",
    "    \n",
    "    说明\n",
    "    ------------\n",
    "    计算 theta 的特定选择的代价。\n",
    "    你需要将 J 设置为代价值。\n",
    "    \"\"\"\n",
    "    \n",
    "    # 初始化一些有用的值\n",
    "    m = y.size  # 样本数量\n",
    "    \n",
    "    # 你需要正确返回以下变量\n",
    "    J = 0\n",
    "    \n",
    "    # ====================== 在此处填写代码 =====================\n",
    "    J = np.sum((X.dot(theta) - y) ** 2) / (2 * m)\n",
    "    \n",
    "    \n",
    "    # ===========================================================\n",
    "    return J\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "完成函数后，下一步将使用两种不同的 $\\theta$ 初始化运行 `computeCost` 两次。你将看到屏幕上打印的代价。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With theta = [0, 0] \n",
      "Cost computed = 32.07\n",
      "Expected cost value (approximately) 32.07\n",
      "\n",
      "With theta = [-1, 2]\n",
      "Cost computed = 54.24\n",
      "Expected cost value (approximately) 54.24\n"
     ]
    }
   ],
   "source": [
    "J = computeCost(X, y, theta=np.array([0.0, 0.0]))\n",
    "print('With theta = [0, 0] \\nCost computed = %.2f' % J)\n",
    "print('Expected cost value (approximately) 32.07\\n')\n",
    "\n",
    "# 进一步测试代价函数\n",
    "J = computeCost(X, y, theta=np.array([-1, 2]))\n",
    "print('With theta = [-1, 2]\\nCost computed = %.2f' % J)\n",
    "print('Expected cost value (approximately) 54.24')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*你现在应该通过执行以下单元格提交你的解决方案。*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "本地评分结果\n",
      "\n",
      "                                  Part Name | Score    | Result\n",
      "                                  --------- | -------- | --------\n",
      "                           Warm up exercise | 20       | 通过\n",
      "          Computing Cost (for one variable) | 20       | 通过\n",
      "        Gradient Descent (for one variable) | 0        | 未通过\n",
      "                      Feature Normalization | 0        | 未通过\n",
      "    Computing Cost (for multiple variables) | 0        | 未通过\n",
      "  Gradient Descent (for multiple variables) | 0        | 未通过\n",
      "                           Normal Equations | 0        | 未通过\n",
      "\n",
      "总分: 40 / 140\n"
     ]
    }
   ],
   "source": [
    "grader[2] = computeCost\n",
    "grader.grade()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"section3\"></a>\n",
    "#### 2.2.4 梯度下降\n",
    "\n",
    "接下来，你将完成一个实现梯度下降的函数。\n",
    "循环结构已经为你编写好，你只需在每次迭代中提供对 $\\theta$ 的更新。\n",
    "\n",
    "在编程时，请确保你理解你试图优化的内容以及正在更新的内容。请记住，代价函数 $J(\\theta)$ 是由向量 $\\theta$ 参数化的，而不是由 $X$ 和 $y$ 参数化的。也就是说，我们通过改变向量 $\\theta$ 的值来最小化 $J(\\theta)$ 的值，而不是通过改变 $X$ 或 $y$ 的值。[如果不确定，请参考本笔记本中的公式](#section2) 和视频讲座。验证梯度下降是否正确工作的一个好方法是查看 $J(\\theta)$ 的值，并检查它是否随着每一步骤而减少。\n",
    "\n",
    "函数 `gradientDescent` 的起始代码在每次迭代中调用 `computeCost` 并将代价保存到一个 `python` 列表中。如果你正确实现了梯度下降和 `computeCost`，那么 $J(\\theta)$ 的值永远不会增加，并且应该在算法结束时收敛到一个稳定值。\n",
    "\n",
    "<div class=\"alert alert-box alert-warning\">\n",
    "**`numpy` 中的向量和矩阵** - 重要的实现注意事项\n",
    "\n",
    "在 `numpy` 中，向量是一维数组，例如 `np.array([1, 2, 3])` 是一个向量。矩阵是二维数组，例如 `np.array([[1, 2, 3], [4, 5, 6]])` 是一个矩阵。然而，以下内容仍然被认为是矩阵 `np.array([[1, 2, 3]])`，因为它有两个维度，即使它的形状是 1x3（看起来像一个向量）。\n",
    "\n",
    "鉴于上述内容，我们将用于所有矩阵/向量乘法的函数 `np.dot` 具有以下属性：\n",
    "- 它总是对向量执行内积。如果 `x=np.array([1, 2, 3])`，那么 `np.dot(x, x)` 是一个标量。\n",
    "- 对于矩阵-向量乘法，如果 $X$ 是一个 $m\\times n$ 矩阵，$y$ 是一个长度为 $m$ 的向量，那么操作 `np.dot(y, X)` 将 $y$ 视为一个 $1 \\times m$ 矩阵。另一方面，如果 $y$ 是一个长度为 $n$ 的向量，那么操作 `np.dot(X, y)` 将 $y$ 视为一个 $n \\times 1$ 矩阵。\n",
    "- 可以使用 `y[None]` 或 `[y[np.newaxis]` 将向量提升为矩阵。也就是说，如果 `y = np.array([1, 2, 3])` 是一个大小为 3 的向量，那么 `y[None, :]` 是一个形状为 $1 \\times 3$ 的矩阵。我们可以使用 `y[:, None]` 来获得一个形状为 $3 \\times 1$ 的矩阵。\n",
    "<div>\n",
    "<a id=\"gradientDescent\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradientDescent(X, y, theta, alpha, num_iters):\n",
    "    \"\"\"\n",
    "    执行梯度下降以学习 `theta`。通过学习率 `alpha` 进行 `num_iters` 次梯度更新来更新 theta。\n",
    "    \n",
    "    参数\n",
    "    ----------\n",
    "    X : array_like\n",
    "        输入数据集，形状为 (m x n+1)。\n",
    "    \n",
    "    y : array_like\n",
    "        给定特征的值。形状为 (m, ) 的向量。\n",
    "    \n",
    "    theta : array_like\n",
    "        线性回归参数的初始值。\n",
    "        形状为 (n+1, ) 的向量。\n",
    "    \n",
    "    alpha : float\n",
    "        学习率。\n",
    "    \n",
    "    num_iters : int\n",
    "        梯度下降的迭代次数。\n",
    "    \n",
    "    返回值\n",
    "    -------\n",
    "    theta : array_like\n",
    "        学到的线性回归参数。形状为 (n+1, ) 的向量。\n",
    "    \n",
    "    J_history : list\n",
    "        一个 Python 列表，用于保存每次迭代后的代价函数值。\n",
    "    \n",
    "    说明\n",
    "    ------------\n",
    "    对参数向量 theta 执行一次梯度更新。\n",
    "\n",
    "    在调试时，可以在此处打印出代价函数 (computeCost) 和梯度的值。\n",
    "    \"\"\"\n",
    "    # 初始化一些有用的值\n",
    "    m = y.shape[0]  # 训练样本的数量\n",
    "    \n",
    "    # 创建 theta 的副本，以避免更改原始数组，因为 numpy 数组是通过引用传递给函数的\n",
    "    theta = theta.copy()\n",
    "    \n",
    "    J_history = [] # 使用一个 Python 列表来保存每次迭代的代价\n",
    "    \n",
    "    for i in range(num_iters):\n",
    "        # ==================== 在此处填写你的代码 =================================\n",
    "        \n",
    "        # 计算梯度\n",
    "        grad = (1/m) * X.T @ (X @ theta - y)\n",
    "        \n",
    "        # 更新 theta\n",
    "        theta = theta - alpha * grad\n",
    "        \n",
    "        # =====================================================================\n",
    "        \n",
    "        # 在每次迭代中保存代价 J\n",
    "        J_history.append(computeCost(X, y, theta))\n",
    "    \n",
    "    return theta, J_history\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "完成后调用实现的 `gradientDescent` 函数并打印计算出的 $\\theta$。我们将 $\\theta$ 参数初始化为 0，学习率 $\\alpha$ 初始化为 0.01。执行以下单元格以检查你的代码。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Theta found by gradient descent: -3.6303, 1.1664\n",
      "Expected theta values (approximately): [-3.6303, 1.1664]\n"
     ]
    }
   ],
   "source": [
    "# 初始化拟合参数\n",
    "theta = np.zeros(2)\n",
    "\n",
    "# 一些梯度下降的设置\n",
    "iterations = 1500  # 迭代次数\n",
    "alpha = 0.01  # 学习率\n",
    "\n",
    "theta, J_history = gradientDescent(X, y, theta, alpha, iterations)\n",
    "print('Theta found by gradient descent: {:.4f}, {:.4f}'.format(*theta))\n",
    "print('Expected theta values (approximately): [-3.6303, 1.1664]')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们将使用你的最终参数绘制线性拟合。结果应如下图所示。\n",
    "\n",
    "![](Figures/regression_result.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 绘制线性拟合\n",
    "plotData(X[:, 1], y)\n",
    "pyplot.plot(X[:, 1], np.dot(X, theta), '-')\n",
    "pyplot.legend(['Training data', 'Linear regression']);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "你的最终 $\\theta$ 值也将用于预测在人口为 35,000 和 70,000 的地区的利润。\n",
    "\n",
    "<div class=\"alert alert-block alert-success\">\n",
    "注意以下代码行使用矩阵乘法，而不是显式求和或循环来计算预测值。这是 `numpy` 中代码向量化的一个示例。\n",
    "</div>\n",
    "\n",
    "<div class=\"alert alert-block alert-success\">\n",
    "注意，`numpy` 函数 `dot` 的第一个参数是一个 Python 列表。`numpy` 可以在显式提供为 `numpy` 函数的参数时，内部将**有效的** Python 列表转换为 numpy 数组。\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For population = 35,000, we predict a profit of 4519.77\n",
      "\n",
      "For population = 70,000, we predict a profit of 45342.45\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 预测人口规模为 35,000 和 70,000 的值\n",
    "predict1 = np.dot([1, 3.5], theta)\n",
    "print('For population = 35,000, we predict a profit of {:.2f}\\n'.format(predict1*10000))\n",
    "\n",
    "predict2 = np.dot([1, 7], theta)\n",
    "print('For population = 70,000, we predict a profit of {:.2f}\\n'.format(predict2*10000))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*你现在应该通过执行下一个单元格提交你的解决方案。*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "本地评分结果\n",
      "\n",
      "                                  Part Name | Score    | Result\n",
      "                                  --------- | -------- | --------\n",
      "                           Warm up exercise | 20       | 通过\n",
      "          Computing Cost (for one variable) | 20       | 通过\n",
      "        Gradient Descent (for one variable) | 20       | 通过\n",
      "                      Feature Normalization | 0        | 未通过\n",
      "    Computing Cost (for multiple variables) | 0        | 未通过\n",
      "  Gradient Descent (for multiple variables) | 0        | 未通过\n",
      "                           Normal Equations | 0        | 未通过\n",
      "\n",
      "总分: 60 / 140\n"
     ]
    }
   ],
   "source": [
    "grader[3] = gradientDescent\n",
    "grader.grade()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 可视化 $J(\\theta)$\n",
    "\n",
    "为了更好地理解代价函数 $J(\\theta)$，你现在将绘制 $\\theta_0$ 和 $\\theta_1$ 值的二维网格上的代价图。你不需要为此部分编写任何新代码，但你应该理解你已经编写的代码是如何创建这些图像的。\n",
    "\n",
    "在下一个单元格中，代码设置为使用你编写的 `computeCost` 函数计算网格值上的 $J(\\theta)$。执行以下单元格后，你将获得一个 $J(\\theta)$ 值的二维数组。然后，这些值将用于使用 matplotlib 的 `plot_surface` 和 `contourf` 函数生成 $J(\\theta)$ 的表面图和等高线图。图像应类似于以下内容：\n",
    "\n",
    "![](Figures/cost_function.png)\n",
    "\n",
    "这些图的目的是向你展示 $J(\\theta)$ 如何随着 $\\theta_0$ 和 $\\theta_1$ 的变化而变化。代价函数 $J(\\theta)$ 是碗状的，并且具有全局最小值。（在等高线图中比在 3D 表面图中更容易看到这一点）。这个最小值是 $\\theta_0$ 和 $\\theta_1$ 的最优点，梯度下降的每一步都会更接近这一点。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 网格范围，我们将在其上计算 J\n",
    "theta0_vals = np.linspace(-10, 10, 100)\n",
    "theta1_vals = np.linspace(-1, 4, 100)\n",
    "\n",
    "# 将 J_vals 初始化为一个全为 0 的矩阵\n",
    "J_vals = np.zeros((theta0_vals.shape[0], theta1_vals.shape[0]))\n",
    "\n",
    "# 填充 J_vals\n",
    "for i, theta0 in enumerate(theta0_vals):\n",
    "    for j, theta1 in enumerate(theta1_vals):\n",
    "        J_vals[i, j] = computeCost(X, y, [theta0, theta1])\n",
    "        \n",
    "# 由于 meshgrids 在 surf 命令中的工作方式，我们需要在调用 surf 之前转置 J_vals，否则轴会被翻转\n",
    "J_vals = J_vals.T\n",
    "\n",
    "# 表面图\n",
    "fig = pyplot.figure(figsize=(12, 5))\n",
    "ax = fig.add_subplot(121, projection='3d')\n",
    "ax.plot_surface(theta0_vals, theta1_vals, J_vals, cmap='viridis')\n",
    "pyplot.xlabel('theta0')\n",
    "pyplot.ylabel('theta1')\n",
    "pyplot.title('表面图')\n",
    "\n",
    "# 等高线图\n",
    "# 将 J_vals 绘制为 15 条等高线，等高线在 0.01 和 100 之间以对数间隔分布\n",
    "ax = pyplot.subplot(122)\n",
    "pyplot.contour(theta0_vals, theta1_vals, J_vals, linewidths=2, cmap='viridis', levels=np.logspace(-2, 3, 20))\n",
    "pyplot.xlabel('theta0')\n",
    "pyplot.ylabel('theta1')\n",
    "pyplot.plot(theta[0], theta[1], 'ro', ms=10, lw=2)\n",
    "pyplot.title('等高线图，显示最小值')\n",
    "pass\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## 3 多变量线性回归\n",
    "\n",
    "在本部分中，你将实现多变量线性回归以预测房屋价格。假设你正在出售你的房屋，并且想知道一个合理的市场价格是多少。一种方法是首先收集最近售出的房屋信息，并建立一个房价模型。\n",
    "\n",
    "文件 `Data/ex1data2.txt` 包含了波特兰市的房价训练集。第一列是房屋的大小（以平方英尺为单位），第二列是卧室的数量，第三列是房屋的价格。\n",
    "\n",
    "<a id=\"section4\"></a>\n",
    "### 3.1 特征归一化\n",
    "\n",
    "我们首先加载并显示该数据集中的一些值。通过查看这些值，请注意房屋大小大约是卧室数量的 1000 倍。当特征的数量级差异较大时，首先执行特征缩放可以使梯度下降收敛得更快。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  X[:,0] X[:, 1]         y\n",
      "--------------------------\n",
      "    2104       3    399900\n",
      "    1600       3    329900\n",
      "    2400       3    369000\n",
      "    1416       2    232000\n",
      "    3000       4    539900\n",
      "    1985       4    299900\n",
      "    1534       3    314900\n",
      "    1427       3    198999\n",
      "    1380       3    212000\n",
      "    1494       3    242500\n"
     ]
    }
   ],
   "source": [
    "# 加载数据\n",
    "data = np.loadtxt(os.path.join('Data', 'ex1data2.txt'), delimiter=',')\n",
    "X = data[:, :2]\n",
    "y = data[:, 2]\n",
    "m = y.size\n",
    "\n",
    "# 打印一些数据点\n",
    "print('{:>8s}{:>8s}{:>10s}'.format('X[:,0]', 'X[:, 1]', 'y'))\n",
    "print('-'*26)\n",
    "for i in range(10):\n",
    "    print('{:8.0f}{:8.0f}{:10.0f}'.format(X[i, 0], X[i, 1], y[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "你的任务是完成 `featureNormalize` 函数中的代码：\n",
    "- 从数据集中减去每个特征的均值。\n",
    "- 在减去均值后，还需要将特征值除以其各自的“标准差”进行缩放。\n",
    "\n",
    "标准差是一种衡量特定特征值范围内变化程度的方法（大多数数据点将位于均值的 ±2 个标准差范围内）；这是取值范围（最大值-最小值）的替代方法。在 `numpy` 中，你可以使用 `std` 函数来计算标准差。\n",
    "\n",
    "例如，数量 `X[:, 0]` 包含训练集中所有的 $x_1$（房屋大小）值，因此 `np.std(X[:, 0])` 计算房屋大小的标准差。\n",
    "在调用 `featureNormalize` 函数时，与 $x_0 = 1$ 对应的额外列 1 尚未添加到 $X$ 中。\n",
    "\n",
    "你需要对所有特征执行此操作，并且你的代码应适用于所有大小的数据集（任意数量的特征/示例）。请注意，矩阵 $X$ 的每一列对应一个特征。\n",
    "\n",
    "<div class=\"alert alert-block alert-warning\">\n",
    "**实现注意事项：** 在归一化特征时，存储用于归一化的值（均值和标准差）非常重要。在从模型中学习到参数后，我们通常希望预测之前未见过的房屋价格。给定一个新的 x 值（客厅面积和卧室数量），我们必须首先使用从训练集中先前计算的均值和标准差对 x 进行归一化。\n",
    "</div>\n",
    "<a id=\"featureNormalize\"></a>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def  featureNormalize(X):\n",
    "    \"\"\"\n",
    "    对 X 中的特征进行归一化。返回一个归一化后的版本，其中每个特征的均值为 0，标准差为 1。\n",
    "    这是在使用学习算法时一个常见的预处理步骤。\n",
    "    \n",
    "    参数\n",
    "    ----------\n",
    "    X : array_like\n",
    "        数据集，形状为 (m x n)。\n",
    "    \n",
    "    返回值\n",
    "    -------\n",
    "    X_norm : array_like\n",
    "        归一化后的数据集，形状为 (m x n)。\n",
    "    \n",
    "    说明\n",
    "    ------------\n",
    "    首先，对于每个特征维度，计算该特征的均值，并从数据集中减去该均值，将均值存储在 mu 中。\n",
    "    接下来，计算每个特征的标准差，并将每个特征除以其标准差，将标准差存储在 sigma 中。\n",
    "    \n",
    "    注意，X 是一个矩阵，其中每列是一个特征，每行是一个样本。你需要分别对每个特征进行归一化。\n",
    "    \n",
    "    提示\n",
    "    ----\n",
    "    你可能会发现 'np.mean' 和 'np.std' 函数很有用。\n",
    "    \"\"\"\n",
    "    # 你需要正确设置这些值\n",
    "    X_norm = X.copy()\n",
    "    mu = np.zeros(X.shape[1])\n",
    "    sigma = np.zeros(X.shape[1])\n",
    "\n",
    "    # =========================== 在此处填写代码 =====================\n",
    "    # 计算每个特征的均值\n",
    "    mu = np.mean(X, axis=0)\n",
    "    \n",
    "    # 计算每个特征的标准差\n",
    "    sigma = np.std(X, axis=0)\n",
    "    \n",
    "    # 归一化每个特征\n",
    "    X_norm = (X - mu) / sigma\n",
    "    \n",
    "    # ================================================================\n",
    "    return X_norm, mu, sigma\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "执行下一个单元格以运行已实现的 `featureNormalize` 函数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computed mean: [2000.68085106    3.17021277]\n",
      "Computed standard deviation: [7.86202619e+02 7.52842809e-01]\n"
     ]
    }
   ],
   "source": [
    "# 在加载的数据上调用 featureNormalize\n",
    "X_norm, mu, sigma = featureNormalize(X)\n",
    "\n",
    "print('Computed mean:', mu)\n",
    "print('Computed standard deviation:', sigma)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*请提交你的解决方案。*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "本地评分结果\n",
      "\n",
      "                                  Part Name | Score    | Result\n",
      "                                  --------- | -------- | --------\n",
      "                           Warm up exercise | 20       | 通过\n",
      "          Computing Cost (for one variable) | 20       | 通过\n",
      "        Gradient Descent (for one variable) | 20       | 通过\n",
      "                      Feature Normalization | 20       | 通过\n",
      "    Computing Cost (for multiple variables) | 0        | 未通过\n",
      "  Gradient Descent (for multiple variables) | 0        | 未通过\n",
      "                           Normal Equations | 0        | 未通过\n",
      "\n",
      "总分: 80 / 140\n"
     ]
    }
   ],
   "source": [
    "grader[4] = featureNormalize\n",
    "grader.grade()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在测试 `featureNormalize` 函数之后，我们现在将截距项添加到 `X_norm`："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 添加截距项到 X\n",
    "X = np.concatenate([np.ones((m, 1)), X_norm], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"section5\"></a>\n",
    "### 3.2 梯度下降\n",
    "\n",
    "之前，你已经在单变量回归问题上实现了梯度下降。现在唯一的区别是矩阵 $X$ 中多了一个特征。假设函数和批量梯度下降更新规则保持不变。\n",
    "\n",
    "你需要完成函数 `computeCostMulti` 和 `gradientDescentMulti` 的代码，以实现多变量线性回归的代价函数和梯度下降。如果你在前一部分（单变量）中的代码已经支持多变量，你也可以在这里使用它。\n",
    "确保你的代码支持任意数量的特征，并且是良好向量化的。\n",
    "你可以使用 `numpy` 数组的 `shape` 属性来找出数据集中有多少特征。\n",
    "\n",
    "<div class=\"alert alert-block alert-warning\">\n",
    "**实现注意事项：** 在多变量情况下，代价函数也可以写成以下向量化形式：\n",
    "\n",
    "$$ J(\\theta) = \\frac{1}{2m}(X\\theta - \\vec{y})^T(X\\theta - \\vec{y}) $$\n",
    "\n",
    "其中 \n",
    "\n",
    "$$ X = \\begin{pmatrix}\n",
    "      - (x^{(1)})^T - \\\\\n",
    "      - (x^{(2)})^T - \\\\\n",
    "      \\vdots \\\\\n",
    "      - (x^{(m)})^T - \\\\ \\\\\n",
    "    \\end{pmatrix} \\qquad \\mathbf{y} = \\begin{bmatrix} y^{(1)} \\\\ y^{(2)} \\\\ \\vdots \\\\ y^{(m)} \\\\\\end{bmatrix}$$\n",
    "\n",
    "向量化版本在使用像 `numpy` 这样的数值计算工具时非常高效。如果你擅长矩阵运算，可以自己证明这两种形式是等价的。\n",
    "</div>\n",
    "\n",
    "<a id=\"computeCostMulti\"></a>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeCostMulti(X, y, theta):\n",
    "    \"\"\"\n",
    "    计算多变量线性回归的代价函数。\n",
    "    使用 theta 作为参数来拟合 X 和 y 中的数据点，并计算代价。\n",
    "    \n",
    "    参数\n",
    "    ----------\n",
    "    X : array_like\n",
    "        数据集，形状为 (m x n+1)。\n",
    "    \n",
    "    y : array_like\n",
    "        一个形状为 (m, ) 的向量，表示每个数据点的值。\n",
    "    \n",
    "    theta : array_like\n",
    "        线性回归的参数。一个形状为 (n+1, ) 的向量。\n",
    "    \n",
    "    返回值\n",
    "    -------\n",
    "    J : float\n",
    "        代价函数的值。\n",
    "    \n",
    "    说明\n",
    "    ------------\n",
    "    计算 theta 的特定选择的代价。你需要将 J 设置为代价值。\n",
    "    \"\"\"\n",
    "    # 初始化一些有用的值\n",
    "    m = y.shape[0] # 训练样本的数量\n",
    "    \n",
    "    # 你需要正确返回以下变量\n",
    "    J = 0\n",
    "    \n",
    "    # ======================= 在此处填写代码 ===========================\n",
    "    # 计算预测值\n",
    "    h = X @ theta\n",
    "    \n",
    "    # 计算代价\n",
    "    J = (1/(2*m)) * np.sum((h - y)**2)\n",
    "    \n",
    "    \n",
    "    \n",
    "    # ==================================================================\n",
    "    return J\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*你现在应该提交你的解决方案。*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "本地评分结果\n",
      "\n",
      "                                  Part Name | Score    | Result\n",
      "                                  --------- | -------- | --------\n",
      "                           Warm up exercise | 20       | 通过\n",
      "          Computing Cost (for one variable) | 20       | 通过\n",
      "        Gradient Descent (for one variable) | 20       | 通过\n",
      "                      Feature Normalization | 20       | 通过\n",
      "    Computing Cost (for multiple variables) | 20       | 通过\n",
      "  Gradient Descent (for multiple variables) | 0        | 未通过\n",
      "                           Normal Equations | 0        | 未通过\n",
      "\n",
      "总分: 100 / 140\n"
     ]
    }
   ],
   "source": [
    "grader[5] = computeCostMulti\n",
    "grader.grade()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"gradientDescentMulti\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradientDescentMulti(X, y, theta, alpha, num_iters):\n",
    "    \"\"\"\n",
    "    执行梯度下降以学习 theta。\n",
    "    通过学习率 alpha 进行 num_iters 次梯度更新来更新 theta。\n",
    "        \n",
    "    参数\n",
    "    ----------\n",
    "    X : array_like\n",
    "        数据集，形状为 (m x n+1)。\n",
    "    \n",
    "    y : array_like\n",
    "        一个形状为 (m, ) 的向量，表示每个数据点的值。\n",
    "    \n",
    "    theta : array_like\n",
    "        线性回归的参数。一个形状为 (n+1, ) 的向量。\n",
    "    \n",
    "    alpha : float\n",
    "        梯度下降的学习率。\n",
    "    \n",
    "    num_iters : int\n",
    "        梯度下降的迭代次数。\n",
    "    \n",
    "    返回值\n",
    "    -------\n",
    "    theta : array_like\n",
    "        学到的线性回归参数。一个形状为 (n+1, ) 的向量。\n",
    "    \n",
    "    J_history : list\n",
    "        一个 Python 列表，用于保存每次迭代后的代价函数值。\n",
    "    \n",
    "    说明\n",
    "    ------------\n",
    "    对参数向量 theta 执行一次梯度更新。\n",
    "\n",
    "    在调试时，可以在此处打印出代价函数 (computeCost) 和梯度的值。\n",
    "    \"\"\"\n",
    "    # 初始化一些有用的值\n",
    "    m = y.shape[0] # 训练样本的数量\n",
    "    \n",
    "    # 创建 theta 的副本，以避免更改原始数组，因为 numpy 数组是通过引用传递给函数的\n",
    "    theta = theta.copy()\n",
    "    \n",
    "    J_history = []\n",
    "    \n",
    "    for i in range(num_iters):\n",
    "        # ======================= 在此处填写代码 ==========================\n",
    "        # 计算梯度\n",
    "        grad = (1/m) * X.T @ (X @ theta - y)\n",
    "        \n",
    "        # 更新 theta\n",
    "        theta = theta - alpha * grad\n",
    "        \n",
    "        \n",
    "        # =================================================================\n",
    "        \n",
    "        # 在每次迭代中保存代价 J\n",
    "        J_history.append(computeCostMulti(X, y, theta))\n",
    "    \n",
    "    return theta, J_history\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*你现在应该提交你的解决方案。*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "本地评分结果\n",
      "\n",
      "                                  Part Name | Score    | Result\n",
      "                                  --------- | -------- | --------\n",
      "                           Warm up exercise | 20       | 通过\n",
      "          Computing Cost (for one variable) | 20       | 通过\n",
      "        Gradient Descent (for one variable) | 20       | 通过\n",
      "                      Feature Normalization | 20       | 通过\n",
      "    Computing Cost (for multiple variables) | 20       | 通过\n",
      "  Gradient Descent (for multiple variables) | 20       | 通过\n",
      "                           Normal Equations | 0        | 未通过\n",
      "\n",
      "总分: 120 / 140\n"
     ]
    }
   ],
   "source": [
    "grader[6] = gradientDescentMulti\n",
    "grader.grade()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2.1 可选（未评分）练习：选择学习率\n",
    "\n",
    "在本部分练习中，你将尝试为数据集选择不同的学习率，并找到一个能够快速收敛的学习率。你可以通过修改以下代码并更改设置学习率的部分来调整学习率。\n",
    "\n",
    "使用你实现的 `gradientDescentMulti` 函数，并在所选学习率下运行大约 50 次迭代。该函数还应返回 $J(\\theta)$ 值的历史记录，存储在向量 $J$ 中。\n",
    "\n",
    "在最后一次迭代后，将 $J$ 值与迭代次数绘制在图上。\n",
    "\n",
    "如果你选择的学习率在一个合适的范围内，你的图表应类似于下图。\n",
    "\n",
    "![](Figures/learning_rate.png)\n",
    "\n",
    "如果你的图表看起来非常不同，尤其是如果 $J(\\theta)$ 的值增加甚至发散，请调整你的学习率并重试。我们建议尝试以对数刻度的学习率 $\\alpha$，每次以大约 3 倍的步长递减（例如，0.3、0.1、0.03、0.01 等）。如果这有助于你观察曲线的整体趋势，你可能还需要调整运行的迭代次数。\n",
    "\n",
    "<div class=\"alert alert-block alert-warning\">\n",
    "**实现注意事项：** 如果你的学习率过大，$J(\\theta)$ 可能会发散并“爆炸”，导致值过大而无法进行计算。在这些情况下，`numpy` 通常会返回 NaN。NaN 表示“不是一个数字”，通常由涉及 −∞ 和 +∞ 的未定义操作引起。\n",
    "</div>\n",
    "\n",
    "<div class=\"alert alert-block alert-warning\">\n",
    "**MATPLOTLIB 提示：** 为了比较不同学习率如何影响收敛，在同一图中绘制多个学习率的 $J$ 是很有帮助的。这可以通过将 `alpha` 设置为一个 Python 列表，并在该列表中的值上循环，在每次循环中调用 plot 函数来实现。使用图例来区分图中的不同线条也很有用。在线搜索 `pyplot.legend` 以获取有关在 `matplotlib` 中显示图例的帮助。\n",
    "</div>\n",
    "\n",
    "注意随着学习率的变化，收敛曲线的变化。对于较小的学习率，你会发现梯度下降需要很长时间才能收敛到最优值。相反，对于较大的学习率，梯度下降可能无法收敛，甚至可能发散！\n",
    "使用你找到的最佳学习率，运行脚本直到收敛以找到 $\\theta$ 的最终值。接下来，使用此 $\\theta$ 值预测一个 1650 平方英尺、3 间卧室的房屋价格。稍后你将使用此值来检查你对正规方程的实现。进行此预测时，请不要忘记对特征进行归一化！\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "通过梯度下降计算的 theta: [340412.65957447 109447.79558639  -6578.3539709 ]\n",
      "预测的 1650 平方英尺、3 间卧室房屋价格 (使用梯度下降): $180909540\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "说明\n",
    "------------\n",
    "我们为你提供了以下初始代码，该代码使用特定的学习率 (alpha) 运行梯度下降。\n",
    "\n",
    "你的任务是首先确保你的函数 - `computeCost` 和 `gradientDescent` 已经可以与此初始代码一起工作，并支持多变量。\n",
    "\n",
    "之后，尝试使用不同的 alpha 值运行梯度下降，看看哪个值能给你最佳结果。\n",
    "\n",
    "最后，你应该完成末尾的代码，以预测一个 1650 平方英尺、3 间卧室的房屋价格。\n",
    "\n",
    "提示\n",
    "----\n",
    "在预测时，请确保你执行了相同的特征归一化。\n",
    "\"\"\"\n",
    "# 选择一个 alpha 值 - 修改此处\n",
    "alpha = 0.1\n",
    "num_iters = 400\n",
    "\n",
    "# 初始化 theta 并运行梯度下降\n",
    "theta = np.zeros(3)\n",
    "theta, J_history = gradientDescentMulti(X, y, theta, alpha, num_iters)\n",
    "\n",
    "# 绘制收敛图\n",
    "pyplot.plot(np.arange(len(J_history)), J_history, lw=2)\n",
    "pyplot.xlabel('迭代次数')\n",
    "pyplot.ylabel('代价 J')\n",
    "\n",
    "# 显示梯度下降的结果\n",
    "print('通过梯度下降计算的 theta: {:s}'.format(str(theta)))\n",
    "price = 0\n",
    "\n",
    "# 估算一个 1650 平方英尺、3 间卧室房屋的价格\n",
    "# ======================= 在此处填写你的代码 ===========================\n",
    "# 请记住，X 的第一列是全为 1 的。\n",
    "# 因此，它不需要归一化。\n",
    "# 归一化特征\n",
    "X_norm, mu, sigma = featureNormalize(X[:, 1:])\n",
    "    \n",
    "# 在归一化特征上添加偏置项\n",
    "X_norm = np.column_stack((np.ones(X_norm.shape[0]), X_norm))\n",
    "    \n",
    "# 初始化 theta\n",
    "theta = np.zeros(X_norm.shape[1])\n",
    "    \n",
    "# 运行梯度下降\n",
    "theta, J_history = gradientDescentMulti(X_norm, y, theta, alpha, num_iters)\n",
    "    \n",
    "# 预测价格\n",
    "price = np.array([1, (1650 - mu[0])/sigma[0], (3 - mu[1])/sigma[1]]) @ theta\n",
    "\n",
    "# ===================================================================\n",
    "\n",
    "print('预测的 1650 平方英尺、3 间卧室房屋价格 (使用梯度下降): ${:.0f}'.format(price))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*你不需要为此可选（未评分）部分提交任何解决方案。*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"section7\"></a>\n",
    "### 3.3 正规方程\n",
    "\n",
    "在讲座视频中，你了解到线性回归的闭式解为：\n",
    "\n",
    "$$ \\theta = \\left( X^T X\\right)^{-1} X^T\\vec{y}$$\n",
    "\n",
    "使用此公式不需要任何特征缩放，你可以通过一次计算获得精确解：不像梯度下降那样需要“循环直到收敛”。\n",
    "\n",
    "首先，我们将重新加载数据以确保变量未被修改。请记住，虽然你不需要对特征进行缩放，但我们仍然需要向 $X$ 矩阵添加一列全为 1 的列，以包含截距项 ($\\theta_0$)。下一单元格中的代码将为你添加全为 1 的列到 X。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加载数据\n",
    "data = np.loadtxt(os.path.join('Data', 'ex1data2.txt'), delimiter=',')\n",
    "X = data[:, :2]\n",
    "y = data[:, 2]\n",
    "m = y.size\n",
    "X = np.concatenate([np.ones((m, 1)), X], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "完成下面函数 `normalEqn` 的代码，使用上述公式计算 $\\theta$。\n",
    "\n",
    "<a id=\"normalEqn\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalEqn(X, y):\n",
    "    \"\"\"\n",
    "    使用正规方程计算线性回归的闭式解。\n",
    "    \n",
    "    参数\n",
    "    ----------\n",
    "    X : array_like\n",
    "        数据集，形状为 (m x n+1)。\n",
    "    \n",
    "    y : array_like\n",
    "        每个数据点的值。形状为 (m, ) 的向量。\n",
    "    \n",
    "    返回值\n",
    "    -------\n",
    "    theta : array_like\n",
    "        估计的线性回归参数。形状为 (n+1, ) 的向量。\n",
    "    \n",
    "    说明\n",
    "    ------------\n",
    "    完成代码以计算线性回归的闭式解，并将结果存储在 theta 中。\n",
    "    \n",
    "    提示\n",
    "    ----\n",
    "    查阅函数 `np.linalg.pinv` 以计算矩阵的逆。\n",
    "    \"\"\"\n",
    "    theta = np.zeros(X.shape[1])\n",
    "    \n",
    "    # ===================== 在此处填写代码 ============================\n",
    "    # 计算正规方程的闭式解\n",
    "    theta = np.linalg.pinv(X.T @ X) @ X.T @ y\n",
    "    \n",
    "    # =================================================================\n",
    "    return theta\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*你现在应该提交你的解决方案。*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "本地评分结果\n",
      "\n",
      "                                  Part Name | Score    | Result\n",
      "                                  --------- | -------- | --------\n",
      "                           Warm up exercise | 20       | 通过\n",
      "          Computing Cost (for one variable) | 20       | 通过\n",
      "        Gradient Descent (for one variable) | 20       | 通过\n",
      "                      Feature Normalization | 20       | 通过\n",
      "    Computing Cost (for multiple variables) | 20       | 通过\n",
      "  Gradient Descent (for multiple variables) | 20       | 通过\n",
      "                           Normal Equations | 20       | 通过\n",
      "\n",
      "总分: 140 / 140\n"
     ]
    }
   ],
   "source": [
    "grader[7] = normalEqn\n",
    "grader.grade()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "可选（未评分）练习：现在，一旦你使用此方法找到 $\\theta$，请使用它为一个 1650 平方英尺、3 间卧室的房屋进行价格预测。你应该发现，这与使用梯度下降拟合的模型（在第 3.2.1 节中）获得的预测价格相同。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Theta computed from the normal equations: [89597.90954435   139.21067402 -8738.01911278]\n",
      "Predicted price of a 1650 sq-ft, 3 br house (using normal equations): $293081\n"
     ]
    }
   ],
   "source": [
    "# 使用正规方程计算参数\n",
    "theta = normalEqn(X, y)\n",
    "\n",
    "# 显示正规方程的结果\n",
    "print('Theta computed from the normal equations: {:s}'.format(str(theta)))\n",
    "\n",
    "# 估算一个 1650 平方英尺、3 间卧室房屋的价格\n",
    "# ====================== 在此处填写你的代码 ======================\n",
    "# 计算价格\n",
    "price = np.array([1, 1650, 3]) @ theta\n",
    "\n",
    "# ============================================================\n",
    "\n",
    "print('Predicted price of a 1650 sq-ft, 3 br house (using normal equations): ${:.0f}'.format(price))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
